{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'dev_train_len': 25*10**3,\n",
    "    'dev_validation_len': 5*10**3,\n",
    "    'learning_rate': 0.001,\n",
    "    'epochs': 100,\n",
    "    'embedding_dim': 100,\n",
    "    'batch_size': 32,\n",
    "    'dropout': 0.2,\n",
    "    'optimizer': 'Adam',\n",
    "    'num_layers': 2\n",
    "}\n",
    "\n",
    "cfg['hidden_dim'] = cfg['embedding_dim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV_TRAIN_LEN = cfg['dev_train_len']\n",
    "DEV_VALIDATION_LEN = cfg['dev_validation_len']\n",
    "LEARNING_RATE = cfg['learning_rate']\n",
    "EPOCHS = cfg['epochs']\n",
    "BATCH_SIZE = cfg['batch_size']\n",
    "DROPOUT = cfg['dropout']\n",
    "OPTIMIZER = cfg['optimizer']\n",
    "NUM_LAYERS = cfg['num_layers']\n",
    "HIDDEN_DIM = cfg['hidden_dim']\n",
    "EMBEDDING_DIM = cfg['embedding_dim']\n",
    "\n",
    "DIR = '/scratch/shu7bh/RES/Word/1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshu7bh\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home2/shu7bh/Courses/ANLP/Assignments/2/wandb/run-20230922_154116-8lovywsf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/shu7bh/ELMO/runs/8lovywsf' target=\"_blank\">WordEmb</a></strong> to <a href='https://wandb.ai/shu7bh/ELMO' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/shu7bh/ELMO' target=\"_blank\">https://wandb.ai/shu7bh/ELMO</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/shu7bh/ELMO/runs/8lovywsf' target=\"_blank\">https://wandb.ai/shu7bh/ELMO/runs/8lovywsf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/shu7bh/ELMO/runs/8lovywsf?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f4fa1d1db10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"ELMo\", name=\"WordEmb\", config=cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(DIR):\n",
    "    os.makedirs(DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.downloader import load\n",
    "\n",
    "glove_dict = {\n",
    "    '50': 'glove-wiki-gigaword-50',\n",
    "    '100': 'glove-wiki-gigaword-100',\n",
    "    '200': 'glove-wiki-gigaword-200'\n",
    "}\n",
    "\n",
    "glove_dict[str(EMBEDDING_DIM)] = load(glove_dict[str(EMBEDDING_DIM)])\n",
    "glove = glove_dict[str(EMBEDDING_DIM)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def normalize_unicode(text: str) -> str:\n",
    "    return unicodedata.normalize('NFD', text)\n",
    "\n",
    "def clean_data(text: str) -> str:\n",
    "    text = normalize_unicode(text.lower().strip())\n",
    "    text = re.sub(r\"([.!?])\", r\" \\1\", text)\n",
    "    text = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", text)\n",
    "    return text\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "freq_words = dict()\n",
    "\n",
    "def tokenize_data(text: str, create_unique_words: bool) -> list:\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in word_tokenize(text)]\n",
    "    tokens = [token if token in glove else '<unk>' for token in tokens]\n",
    "\n",
    "    if '<unk>' in tokens:\n",
    "        return tokens\n",
    "\n",
    "    if create_unique_words:\n",
    "        for token in tokens:\n",
    "            if token not in freq_words:\n",
    "                freq_words[token] = 1\n",
    "            else:\n",
    "                freq_words[token] += 1\n",
    "    return tokens\n",
    "\n",
    "def replace_words(tokens: list, filter_rare_words: bool) -> list:\n",
    "    tokens = [token if token in freq_words else '<unk>' for token in tokens]\n",
    "    if filter_rare_words:\n",
    "        tokens = [token if freq_words[token] >= 4 else '<unk>' for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "def read_data(path: str, create_unique_words, filter_rare_words) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "    df['Description'] = df['Description'].apply(clean_data)\n",
    "    df['Description'] = df['Description'].apply(tokenize_data, create_unique_words=create_unique_words)\n",
    "\n",
    "    df = df[df['Description'].apply(lambda x: '<unk>' not in x)]\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    df['Class Index'] = df['Class Index'].apply(lambda x: x-1)\n",
    "    ydf = df.copy(deep=True)\n",
    "    ydf['Description'] = ydf['Description'].apply(replace_words, filter_rare_words=filter_rare_words)\n",
    "    return df, ydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21489\n"
     ]
    }
   ],
   "source": [
    "freq_words = dict()\n",
    "xdf, ydf = read_data(\n",
    "    'data/train.csv', \n",
    "    create_unique_words=True, \n",
    "    filter_rare_words=True\n",
    ")\n",
    "\n",
    "unique_words = set()\n",
    "for tokens in ydf['Description']:\n",
    "    unique_words.update(tokens)\n",
    "print(len(unique_words))\n",
    "\n",
    "freq_words = dict()\n",
    "for token in unique_words:\n",
    "    freq_words[token] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Index</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>[london, british, airline, magnate, richard, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>[regardless, space, competition, are, poised, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[cbs, million, of, folded, paper, crane, flutt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[in, the, time, it, take, you, to, read, this,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[washington, a, highly, classified, u, intelli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101981</th>\n",
       "      <td>1</td>\n",
       "      <td>[toronto, reuters, national, hockey, league, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101982</th>\n",
       "      <td>3</td>\n",
       "      <td>[com, september, am, pt, ., there, s, no, doub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101983</th>\n",
       "      <td>0</td>\n",
       "      <td>[pakistani, security, force, have, arrested, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101984</th>\n",
       "      <td>3</td>\n",
       "      <td>[palmsource, finally, unveiled, it, new, o, ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101985</th>\n",
       "      <td>3</td>\n",
       "      <td>[japanese, electronics, giant, nec, corp, ha, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101986 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Class Index                                        Description\n",
       "0                 3  [london, british, airline, magnate, richard, b...\n",
       "1                 3  [regardless, space, competition, are, poised, ...\n",
       "2                 0  [cbs, million, of, folded, paper, crane, flutt...\n",
       "3                 3  [in, the, time, it, take, you, to, read, this,...\n",
       "4                 0  [washington, a, highly, classified, u, intelli...\n",
       "...             ...                                                ...\n",
       "101981            1  [toronto, reuters, national, hockey, league, t...\n",
       "101982            3  [com, september, am, pt, ., there, s, no, doub...\n",
       "101983            0  [pakistani, security, force, have, arrested, m...\n",
       "101984            3  [palmsource, finally, unveiled, it, new, o, ve...\n",
       "101985            3  [japanese, electronics, giant, nec, corp, ha, ...\n",
       "\n",
       "[101986 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = len(set(xdf['Class Index']))\n",
    "NUM_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21492\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary of all words\n",
    "word_to_idx = {word: idx + 1 for idx, word in enumerate(unique_words)}\n",
    "\n",
    "# Add special tokens\n",
    "word_to_idx['<pad>'] = 0\n",
    "word_to_idx['<sos>'] = len(word_to_idx)\n",
    "word_to_idx['<eos>'] = len(word_to_idx)\n",
    "\n",
    "# Create a dictionary of all words\n",
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
    "\n",
    "# print the length of the word to index mapping\n",
    "print(len(word_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_vec = glove.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_key_to_idx = glove.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_key_to_idx['<pad>'] = len(glove_key_to_idx)\n",
    "glove_key_to_idx['<sos>'] = len(glove_key_to_idx)\n",
    "glove_key_to_idx['<eos>'] = len(glove_key_to_idx)\n",
    "glove_key_to_idx['<unk>'] = len(glove_key_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_idx_to_key = {idx: key for key, idx in glove_key_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "glove_idx_to_vec = glove.vectors\n",
    "\n",
    "pad_vec = np.zeros((1, EMBEDDING_DIM))\n",
    "sos_vec = np.random.rand(1, EMBEDDING_DIM)\n",
    "eos_vec = np.random.rand(1, EMBEDDING_DIM)\n",
    "unk_vec = np.mean(glove_idx_to_vec, axis=0, keepdims=True)\n",
    "\n",
    "glove_idx_to_vec = np.concatenate((glove_idx_to_vec, pad_vec, sos_vec, eos_vec, unk_vec), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_train_raw_x = xdf[:DEV_TRAIN_LEN]\n",
    "dev_train_raw_y = ydf[:DEV_TRAIN_LEN]\n",
    "\n",
    "dev_validation_raw_x = xdf[DEV_TRAIN_LEN:DEV_TRAIN_LEN+DEV_VALIDATION_LEN]\n",
    "dev_validation_raw_y = ydf[DEV_TRAIN_LEN:DEV_TRAIN_LEN+DEV_VALIDATION_LEN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Sentences(Dataset):\n",
    "    def __init__(\n",
    "            self, \n",
    "            adf: pd.DataFrame, \n",
    "            pdf: pd.DataFrame, \n",
    "            word_to_idx: dict,\n",
    "            glove_key_to_idx: dict\n",
    "        ) -> None:\n",
    "\n",
    "        self.Xf = []\n",
    "        self.Xb = []\n",
    "        self.Yf = []\n",
    "        self.Yb = []\n",
    "        self.L = []\n",
    "\n",
    "        for sentence in adf['Description']:\n",
    "            self.Xf += [torch.tensor(\n",
    "                [glove_key_to_idx[w] for w in sentence] + \n",
    "                [glove_key_to_idx['<eos>']]\n",
    "            )]\n",
    "            self.Xb += [torch.tensor(\n",
    "                [glove_key_to_idx['<eos>']] + \n",
    "                [glove_key_to_idx[w] for w in reversed(sentence)]\n",
    "            )]\n",
    "\n",
    "            self.L += [torch.tensor(len(sentence) + 1)]\n",
    "\n",
    "        for sentence in pdf['Description']:\n",
    "            self.Yf += [torch.tensor(\n",
    "                [word_to_idx[w] for w in sentence] + \n",
    "                [word_to_idx['<eos>']] + \n",
    "                [word_to_idx['<pad>']]\n",
    "            )]\n",
    "\n",
    "            self.Yf[-1] = self.Yf[-1][1:]\n",
    "\n",
    "            self.Yb += [torch.tensor(\n",
    "                [word_to_idx[w] for w in reversed(sentence)] +\n",
    "                [word_to_idx['<sos>']]\n",
    "            )]\n",
    "\n",
    "        self.Y = torch.tensor(adf['Class Index'].tolist())\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.Xf)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple:\n",
    "        return self.Xf[idx], self.Xb[idx], self.Y[idx], self.L[idx], self.Yf[idx], self.Yb[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_train_dataset = Sentences(dev_train_raw_x, dev_train_raw_y, word_to_idx, glove_key_to_idx)\n",
    "dev_validation_dataset = Sentences(dev_validation_raw_x, dev_validation_raw_y, word_to_idx, glove_key_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch: list) -> tuple:\n",
    "    xf, xb, y, l, yf, yb = zip(*batch)\n",
    "\n",
    "    xf = torch.nn.utils.rnn.pad_sequence(xf, padding_value=glove_key_to_idx['<pad>'], batch_first=True)\n",
    "    xb = torch.nn.utils.rnn.pad_sequence(xb, padding_value=glove_key_to_idx['<pad>'], batch_first=True)\n",
    "    yf = torch.nn.utils.rnn.pad_sequence(yf, padding_value=word_to_idx['<pad>'], batch_first=True)\n",
    "    yb = torch.nn.utils.rnn.pad_sequence(yb, padding_value=word_to_idx['<pad>'], batch_first=True)\n",
    "    return xf, xb, torch.stack(y), torch.stack(l), yf, yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dev_train_loader = DataLoader(dev_train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "dev_validation_loader = DataLoader(dev_validation_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(idx_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ELMo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Mapping\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class ELMo(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            glove_idx_to_vec: np.ndarray,\n",
    "            idx_to_word: dict,\n",
    "            dropout: float, \n",
    "            num_layers: int, \n",
    "            hidden_dim: int, \n",
    "            word_embed_dim: int,\n",
    "            filename: str = None\n",
    "        ) -> None:\n",
    "\n",
    "        super(ELMo, self).__init__()\n",
    "\n",
    "        self.word_embed = nn.Embedding.from_pretrained(torch.from_numpy(glove_idx_to_vec).float(), padding_idx=glove_key_to_idx['<pad>'])\n",
    "\n",
    "        self.lstmf = nn.LSTM(\n",
    "            input_size=word_embed_dim, \n",
    "            hidden_size=hidden_dim, \n",
    "            num_layers=num_layers, \n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.lstmb = nn.LSTM(\n",
    "            input_size=word_embed_dim, \n",
    "            hidden_size=hidden_dim, \n",
    "            num_layers=num_layers, \n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        del self.state_dict()['word_embed.weight']\n",
    "\n",
    "        if filename:\n",
    "            self.load_state_dict(torch.load(filename), strict=False)\n",
    "\n",
    "    def forward(self, xf: torch.Tensor, xb: torch.Tensor, l: torch.Tensor) -> torch.Tensor:\n",
    "        xf = self.word_embed(xf)\n",
    "        xb = self.word_embed(xb)\n",
    "\n",
    "        input = xf.detach().clone()\n",
    "\n",
    "        xf = pack_padded_sequence(xf, lengths=l, batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        xb = pack_padded_sequence(xb, lengths=l, batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        xf, (hsf, csf) = self.lstmf(xf)\n",
    "        xb, (hsb, csb) = self.lstmb(xb)\n",
    "\n",
    "        xf, _ = pad_packed_sequence(xf, batch_first=True)\n",
    "        xb, _ = pad_packed_sequence(xb, batch_first=True)\n",
    "\n",
    "        xf = self.dropout(xf)\n",
    "        xb = self.dropout(xb)\n",
    "\n",
    "        return xf, xb, input, (hsf, csf), (hsb, csb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience:int = 3, delta:float = 0.001):\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_loss:float = np.inf\n",
    "        self.best_model_pth = 0\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, loss, epoch: int):\n",
    "        should_stop = False\n",
    "\n",
    "        if loss >= self.best_loss - self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter > self.patience:\n",
    "                should_stop = True\n",
    "        else:\n",
    "            self.best_loss = loss\n",
    "            self.counter = 0\n",
    "            self.best_model_pth = epoch\n",
    "        return should_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class LM(nn.Module):\n",
    "    def __init__(self, \n",
    "            hidden_dim: int, \n",
    "            vocab_size: int, \n",
    "            filename: str = None\n",
    "        ) -> None:\n",
    "\n",
    "        super(LM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.elmo = ELMo(\n",
    "            glove_idx_to_vec=glove_idx_to_vec,\n",
    "            idx_to_word=idx_to_word,\n",
    "            dropout=DROPOUT, \n",
    "            num_layers=NUM_LAYERS, \n",
    "            hidden_dim=HIDDEN_DIM,\n",
    "            word_embed_dim=EMBEDDING_DIM\n",
    "        )\n",
    "        self.linear_forward = nn.Linear(hidden_dim, vocab_size)\n",
    "        self.linear_backward = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "        if filename:\n",
    "            self.load_state_dict(torch.load(filename))\n",
    "\n",
    "    def forward(self, xf: torch.Tensor, xb: torch.Tensor, l: torch.Tensor) -> torch.Tensor:\n",
    "        xf, xb, _, _, _ = self.elmo(xf, xb, l)\n",
    "        yf = self.linear_forward(xf)\n",
    "        yb = self.linear_backward(xb)\n",
    "        return yf, yb\n",
    "\n",
    "    def fit(self, train_loader: DataLoader, validation_loader: DataLoader, epochs: int, learning_rate: float, filename: str) -> None:\n",
    "        self.es = EarlyStopping()\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=word_to_idx['<pad>'])\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            print('----------------------------------------')\n",
    "            self._train(train_loader)\n",
    "            loss = self._evaluate(validation_loader)\n",
    "            print(f'Epoch: {epoch + 1} | Loss: {loss:7.4f}')\n",
    "            if self.es(loss, epoch):\n",
    "                break\n",
    "            if self.es.counter == 0:\n",
    "                torch.save(self.elmo.state_dict(), os.path.join(DIR, f'{filename}_elmo.pth'))\n",
    "\n",
    "    def _call(self, xf: torch.Tensor, xb: torch.Tensor, y: torch.Tensor, l: torch.Tensor, yf: torch.Tensor, yb: torch.Tensor) -> torch.Tensor:\n",
    "        xf, xb, y, yf, yb = xf.to(DEVICE), xb.to(DEVICE), y.to(DEVICE), yf.to(DEVICE), yb.to(DEVICE)\n",
    "\n",
    "        yf_hat, yb_hat = self(xf, xb, l)\n",
    "\n",
    "        yf_hat = yf_hat.view(-1, self.vocab_size)\n",
    "        yb_hat = yb_hat.view(-1, self.vocab_size)\n",
    "\n",
    "        yf = yf.view(-1)\n",
    "        yb = yb.view(-1)\n",
    "\n",
    "        loss1 = self.criterion(yf_hat, yf)\n",
    "        loss2 = self.criterion(yb_hat, yb)\n",
    "\n",
    "        loss = (loss1 + loss2) / 2\n",
    "\n",
    "        return loss, loss1, loss2\n",
    "\n",
    "    def _train(self, train_loader: DataLoader) -> None:\n",
    "        self.train()\n",
    "        epoch_loss = []\n",
    "        epoch_loss1 = []\n",
    "        epoch_loss2 = []\n",
    "\n",
    "        pbar = tqdm(train_loader)\n",
    "        for xf, xb, y, l, yf, yb in pbar:\n",
    "\n",
    "            loss, loss1, loss2 = self._call(xf, xb, y, l, yf, yb)\n",
    "            epoch_loss.append(loss.item())\n",
    "            epoch_loss1.append(loss1.item())\n",
    "            epoch_loss2.append(loss2.item())\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            pbar.set_description(f'T Loss: {loss.item():7.4f}, Avg Loss: {np.mean(epoch_loss):7.4f}, Avg Loss1: {np.mean(epoch_loss1):7.4f}, Avg Loss2: {np.mean(epoch_loss2):7.4f}')\n",
    "\n",
    "        wandb.log({'upstream_train_loss': np.mean(epoch_loss), 'upstream_train_lossf': np.mean(epoch_loss1), 'upstream_train_lossb': np.mean(epoch_loss2)})\n",
    "\n",
    "    def _evaluate(self, validation_loader: DataLoader) -> float:\n",
    "        self.eval()\n",
    "        epoch_loss = []\n",
    "        epoch_loss1 = []\n",
    "        epoch_loss2 = []\n",
    "        pbar = tqdm(validation_loader)\n",
    "        with torch.no_grad():\n",
    "            for xf, xb, y, l, yf, yb in pbar:\n",
    "                loss, loss1, loss2 = self._call(xf, xb, y, l, yf, yb)\n",
    "                epoch_loss.append(loss.item())\n",
    "                epoch_loss1.append(loss1.item())\n",
    "                epoch_loss2.append(loss2.item())\n",
    "                pbar.set_description(f'V Loss: {epoch_loss[-1]:7.4f}, Avg Loss: {np.mean(epoch_loss):7.4f}, Avg Loss1: {np.mean(epoch_loss1):7.4f}, Avg Loss2: {np.mean(epoch_loss2):7.4f}, Counter: {self.es.counter}, Best Loss: {self.es.best_loss:7.4f}')\n",
    "\n",
    "        wandb.log({'upstream_validation_loss': np.mean(epoch_loss), 'upstream_validation_lossf': np.mean(epoch_loss1), 'upstream_validation_lossb': np.mean(epoch_loss2)})\n",
    "        return np.mean(epoch_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LM(\n",
      "  (elmo): ELMo(\n",
      "    (word_embed): Embedding(400004, 100, padding_idx=400000)\n",
      "    (lstmf): LSTM(100, 100, num_layers=2, batch_first=True, dropout=0.2)\n",
      "    (lstmb): LSTM(100, 100, num_layers=2, batch_first=True, dropout=0.2)\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (linear_forward): Linear(in_features=100, out_features=21492, bias=True)\n",
      "  (linear_backward): Linear(in_features=100, out_features=21492, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "lm = LM(\n",
    "    hidden_dim=HIDDEN_DIM, \n",
    "    vocab_size=len(word_to_idx), \n",
    "    filename=None\n",
    ").to(DEVICE)\n",
    "print(lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "LM                                       --\n",
       "├─ELMo: 1-1                              --\n",
       "│    └─Embedding: 2-1                    (40,000,400)\n",
       "│    └─LSTM: 2-2                         161,600\n",
       "│    └─LSTM: 2-3                         161,600\n",
       "│    └─Dropout: 2-4                      --\n",
       "├─Linear: 1-2                            2,170,692\n",
       "├─Linear: 1-3                            2,170,692\n",
       "=================================================================\n",
       "Total params: 44,664,984\n",
       "Trainable params: 4,664,584\n",
       "Non-trainable params: 40,000,400\n",
       "================================================================="
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(lm, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  6.7043, Avg Loss:  7.0560, Avg Loss1:  7.0875, Avg Loss2:  7.0245: 100%|██████████| 782/782 [00:24<00:00, 31.37it/s]\n",
      "V Loss:  6.7269, Avg Loss:  6.7380, Avg Loss1:  6.7929, Avg Loss2:  6.6832, Counter: 0, Best Loss:     inf: 100%|██████████| 157/157 [00:01<00:00, 87.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Loss:  6.7380\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  6.3778, Avg Loss:  6.5488, Avg Loss1:  6.6124, Avg Loss2:  6.4851: 100%|██████████| 782/782 [00:24<00:00, 31.39it/s]\n",
      "V Loss:  6.5450, Avg Loss:  6.3578, Avg Loss1:  6.4315, Avg Loss2:  6.2841, Counter: 0, Best Loss:  6.7380: 100%|██████████| 157/157 [00:01<00:00, 93.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Loss:  6.3578\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  6.3790, Avg Loss:  6.2302, Avg Loss1:  6.3075, Avg Loss2:  6.1529: 100%|██████████| 782/782 [00:24<00:00, 31.81it/s]\n",
      "V Loss:  6.3081, Avg Loss:  6.0838, Avg Loss1:  6.1755, Avg Loss2:  5.9922, Counter: 0, Best Loss:  6.3578: 100%|██████████| 157/157 [00:01<00:00, 90.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Loss:  6.0838\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  6.0170, Avg Loss:  5.9797, Avg Loss1:  6.0539, Avg Loss2:  5.9056: 100%|██████████| 782/782 [00:24<00:00, 32.14it/s]\n",
      "V Loss:  5.7735, Avg Loss:  5.8731, Avg Loss1:  5.9345, Avg Loss2:  5.8118, Counter: 0, Best Loss:  6.0838: 100%|██████████| 157/157 [00:01<00:00, 87.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Loss:  5.8731\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  5.8665, Avg Loss:  5.7933, Avg Loss1:  5.8425, Avg Loss2:  5.7440: 100%|██████████| 782/782 [00:24<00:00, 31.66it/s]\n",
      "V Loss:  5.6645, Avg Loss:  5.7347, Avg Loss1:  5.7757, Avg Loss2:  5.6938, Counter: 0, Best Loss:  5.8731: 100%|██████████| 157/157 [00:01<00:00, 89.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Loss:  5.7347\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  5.6988, Avg Loss:  5.6558, Avg Loss1:  5.6912, Avg Loss2:  5.6205: 100%|██████████| 782/782 [00:24<00:00, 32.10it/s]\n",
      "V Loss:  5.8578, Avg Loss:  5.6301, Avg Loss1:  5.6601, Avg Loss2:  5.6001, Counter: 0, Best Loss:  5.7347: 100%|██████████| 157/157 [00:01<00:00, 93.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Loss:  5.6301\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  5.6286, Avg Loss:  5.5482, Avg Loss1:  5.5759, Avg Loss2:  5.5205: 100%|██████████| 782/782 [00:24<00:00, 31.94it/s]\n",
      "V Loss:  5.3921, Avg Loss:  5.5481, Avg Loss1:  5.5719, Avg Loss2:  5.5242, Counter: 0, Best Loss:  5.6301: 100%|██████████| 157/157 [00:01<00:00, 94.01it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Loss:  5.5481\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  5.4339, Avg Loss:  5.4596, Avg Loss1:  5.4820, Avg Loss2:  5.4372: 100%|██████████| 782/782 [00:24<00:00, 31.56it/s]\n",
      "V Loss:  5.4422, Avg Loss:  5.4882, Avg Loss1:  5.5076, Avg Loss2:  5.4688, Counter: 0, Best Loss:  5.5481: 100%|██████████| 157/157 [00:01<00:00, 94.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Loss:  5.4882\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  5.6024, Avg Loss:  5.3843, Avg Loss1:  5.4033, Avg Loss2:  5.3652: 100%|██████████| 782/782 [00:24<00:00, 32.01it/s]\n",
      "V Loss:  5.1706, Avg Loss:  5.4362, Avg Loss1:  5.4516, Avg Loss2:  5.4208, Counter: 0, Best Loss:  5.4882: 100%|██████████| 157/157 [00:01<00:00, 89.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Loss:  5.4362\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  5.6579, Avg Loss:  5.3187, Avg Loss1:  5.3346, Avg Loss2:  5.3029: 100%|██████████| 782/782 [00:24<00:00, 31.92it/s]\n",
      "V Loss:  5.8318, Avg Loss:  5.3961, Avg Loss1:  5.4090, Avg Loss2:  5.3833, Counter: 0, Best Loss:  5.4362: 100%|██████████| 157/157 [00:01<00:00, 89.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Loss:  5.3961\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  4.9186, Avg Loss:  5.2613, Avg Loss1:  5.2752, Avg Loss2:  5.2474: 100%|██████████| 782/782 [00:24<00:00, 31.88it/s]\n",
      "V Loss:  5.0762, Avg Loss:  5.3592, Avg Loss1:  5.3695, Avg Loss2:  5.3489, Counter: 0, Best Loss:  5.3961: 100%|██████████| 157/157 [00:01<00:00, 89.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Loss:  5.3592\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  5.3650, Avg Loss:  5.2103, Avg Loss1:  5.2214, Avg Loss2:  5.1991: 100%|██████████| 782/782 [00:24<00:00, 31.85it/s]\n",
      "V Loss:  5.2506, Avg Loss:  5.3349, Avg Loss1:  5.3430, Avg Loss2:  5.3268, Counter: 0, Best Loss:  5.3592: 100%|██████████| 157/157 [00:01<00:00, 88.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Loss:  5.3349\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  5.1501, Avg Loss:  5.1650, Avg Loss1:  5.1747, Avg Loss2:  5.1553: 100%|██████████| 782/782 [00:24<00:00, 32.09it/s]\n",
      "V Loss:  4.7909, Avg Loss:  5.3072, Avg Loss1:  5.3133, Avg Loss2:  5.3010, Counter: 0, Best Loss:  5.3349: 100%|██████████| 157/157 [00:01<00:00, 87.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Loss:  5.3072\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  5.1352, Avg Loss:  5.1241, Avg Loss1:  5.1325, Avg Loss2:  5.1156: 100%|██████████| 782/782 [00:24<00:00, 31.78it/s]\n",
      "V Loss:  5.5345, Avg Loss:  5.2907, Avg Loss1:  5.2946, Avg Loss2:  5.2869, Counter: 0, Best Loss:  5.3072: 100%|██████████| 157/157 [00:01<00:00, 85.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Loss:  5.2907\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  4.9601, Avg Loss:  5.0871, Avg Loss1:  5.0939, Avg Loss2:  5.0802: 100%|██████████| 782/782 [00:24<00:00, 31.44it/s]\n",
      "V Loss:  4.8806, Avg Loss:  5.2722, Avg Loss1:  5.2779, Avg Loss2:  5.2665, Counter: 0, Best Loss:  5.2907: 100%|██████████| 157/157 [00:01<00:00, 93.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Loss:  5.2722\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  5.0032, Avg Loss:  5.0535, Avg Loss1:  5.0608, Avg Loss2:  5.0463: 100%|██████████| 782/782 [00:24<00:00, 31.87it/s]\n",
      "V Loss:  5.6417, Avg Loss:  5.2615, Avg Loss1:  5.2632, Avg Loss2:  5.2597, Counter: 0, Best Loss:  5.2722: 100%|██████████| 157/157 [00:01<00:00, 90.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Loss:  5.2615\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  5.3579, Avg Loss:  5.0232, Avg Loss1:  5.0291, Avg Loss2:  5.0172: 100%|██████████| 782/782 [00:24<00:00, 31.68it/s]\n",
      "V Loss:  5.4697, Avg Loss:  5.2516, Avg Loss1:  5.2535, Avg Loss2:  5.2496, Counter: 0, Best Loss:  5.2615: 100%|██████████| 157/157 [00:01<00:00, 88.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Loss:  5.2516\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  4.9876, Avg Loss:  4.9937, Avg Loss1:  4.9988, Avg Loss2:  4.9885: 100%|██████████| 782/782 [00:24<00:00, 31.96it/s]\n",
      "V Loss:  5.8891, Avg Loss:  5.2420, Avg Loss1:  5.2438, Avg Loss2:  5.2401, Counter: 0, Best Loss:  5.2516: 100%|██████████| 157/157 [00:01<00:00, 89.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Loss:  5.2420\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  5.0850, Avg Loss:  4.9682, Avg Loss1:  4.9727, Avg Loss2:  4.9636: 100%|██████████| 782/782 [00:24<00:00, 31.61it/s]\n",
      "V Loss:  5.2533, Avg Loss:  5.2332, Avg Loss1:  5.2351, Avg Loss2:  5.2313, Counter: 0, Best Loss:  5.2420: 100%|██████████| 157/157 [00:01<00:00, 89.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Loss:  5.2332\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  4.6605, Avg Loss:  4.9436, Avg Loss1:  4.9475, Avg Loss2:  4.9396: 100%|██████████| 782/782 [00:24<00:00, 32.30it/s]\n",
      "V Loss:  4.7124, Avg Loss:  5.2233, Avg Loss1:  5.2233, Avg Loss2:  5.2233, Counter: 0, Best Loss:  5.2332: 100%|██████████| 157/157 [00:01<00:00, 89.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Loss:  5.2233\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  4.9845, Avg Loss:  4.9216, Avg Loss1:  4.9244, Avg Loss2:  4.9189: 100%|██████████| 782/782 [00:24<00:00, 31.74it/s]\n",
      "V Loss:  5.5309, Avg Loss:  5.2220, Avg Loss1:  5.2218, Avg Loss2:  5.2222, Counter: 0, Best Loss:  5.2233: 100%|██████████| 157/157 [00:01<00:00, 87.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 | Loss:  5.2220\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  4.8437, Avg Loss:  4.9001, Avg Loss1:  4.9026, Avg Loss2:  4.8976: 100%|██████████| 782/782 [00:24<00:00, 31.85it/s]\n",
      "V Loss:  5.2809, Avg Loss:  5.2154, Avg Loss1:  5.2137, Avg Loss2:  5.2172, Counter: 0, Best Loss:  5.2220: 100%|██████████| 157/157 [00:01<00:00, 84.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 | Loss:  5.2154\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  4.8001, Avg Loss:  4.8809, Avg Loss1:  4.8835, Avg Loss2:  4.8783: 100%|██████████| 782/782 [00:24<00:00, 31.56it/s]\n",
      "V Loss:  4.7511, Avg Loss:  5.2089, Avg Loss1:  5.2078, Avg Loss2:  5.2100, Counter: 0, Best Loss:  5.2154: 100%|██████████| 157/157 [00:01<00:00, 89.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 | Loss:  5.2089\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  5.0675, Avg Loss:  4.8619, Avg Loss1:  4.8642, Avg Loss2:  4.8596: 100%|██████████| 782/782 [00:24<00:00, 31.73it/s]\n",
      "V Loss:  5.0860, Avg Loss:  5.2092, Avg Loss1:  5.2074, Avg Loss2:  5.2109, Counter: 0, Best Loss:  5.2089: 100%|██████████| 157/157 [00:01<00:00, 89.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 | Loss:  5.2092\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  5.0145, Avg Loss:  4.8450, Avg Loss1:  4.8466, Avg Loss2:  4.8434: 100%|██████████| 782/782 [00:24<00:00, 31.46it/s]\n",
      "V Loss:  5.2289, Avg Loss:  5.2036, Avg Loss1:  5.2004, Avg Loss2:  5.2067, Counter: 1, Best Loss:  5.2089: 100%|██████████| 157/157 [00:01<00:00, 88.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 | Loss:  5.2036\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  5.0047, Avg Loss:  4.8289, Avg Loss1:  4.8287, Avg Loss2:  4.8291: 100%|██████████| 782/782 [00:24<00:00, 32.53it/s]\n",
      "V Loss:  5.0256, Avg Loss:  5.2031, Avg Loss1:  5.2001, Avg Loss2:  5.2060, Counter: 0, Best Loss:  5.2036: 100%|██████████| 157/157 [00:01<00:00, 90.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 | Loss:  5.2031\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  4.9389, Avg Loss:  4.8123, Avg Loss1:  4.8130, Avg Loss2:  4.8115: 100%|██████████| 782/782 [00:24<00:00, 32.20it/s]\n",
      "V Loss:  5.1432, Avg Loss:  5.2020, Avg Loss1:  5.1972, Avg Loss2:  5.2068, Counter: 1, Best Loss:  5.2036: 100%|██████████| 157/157 [00:01<00:00, 86.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 | Loss:  5.2020\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  4.9711, Avg Loss:  4.7987, Avg Loss1:  4.7979, Avg Loss2:  4.7995: 100%|██████████| 782/782 [00:24<00:00, 31.62it/s]\n",
      "V Loss:  5.0468, Avg Loss:  5.1983, Avg Loss1:  5.1931, Avg Loss2:  5.2035, Counter: 0, Best Loss:  5.2020: 100%|██████████| 157/157 [00:01<00:00, 90.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 | Loss:  5.1983\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  4.8068, Avg Loss:  4.7847, Avg Loss1:  4.7837, Avg Loss2:  4.7857: 100%|██████████| 782/782 [00:24<00:00, 32.07it/s]\n",
      "V Loss:  5.2312, Avg Loss:  5.2004, Avg Loss1:  5.1932, Avg Loss2:  5.2075, Counter: 0, Best Loss:  5.1983: 100%|██████████| 157/157 [00:01<00:00, 92.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 | Loss:  5.2004\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  4.9903, Avg Loss:  4.7713, Avg Loss1:  4.7712, Avg Loss2:  4.7715: 100%|██████████| 782/782 [00:24<00:00, 32.38it/s]\n",
      "V Loss:  4.9253, Avg Loss:  5.1973, Avg Loss1:  5.1887, Avg Loss2:  5.2059, Counter: 1, Best Loss:  5.1983: 100%|██████████| 157/157 [00:01<00:00, 90.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 | Loss:  5.1973\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  4.5905, Avg Loss:  4.7581, Avg Loss1:  4.7560, Avg Loss2:  4.7603: 100%|██████████| 782/782 [00:24<00:00, 31.77it/s]\n",
      "V Loss:  4.7175, Avg Loss:  5.1964, Avg Loss1:  5.1910, Avg Loss2:  5.2017, Counter: 2, Best Loss:  5.1983: 100%|██████████| 157/157 [00:01<00:00, 89.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31 | Loss:  5.1964\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  4.9124, Avg Loss:  4.7478, Avg Loss1:  4.7456, Avg Loss2:  4.7500: 100%|██████████| 782/782 [00:24<00:00, 31.75it/s]\n",
      "V Loss:  4.9001, Avg Loss:  5.1957, Avg Loss1:  5.1865, Avg Loss2:  5.2050, Counter: 0, Best Loss:  5.1964: 100%|██████████| 157/157 [00:01<00:00, 91.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32 | Loss:  5.1957\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  4.7021, Avg Loss:  4.7350, Avg Loss1:  4.7323, Avg Loss2:  4.7377: 100%|██████████| 782/782 [00:24<00:00, 31.79it/s]\n",
      "V Loss:  5.7860, Avg Loss:  5.1996, Avg Loss1:  5.1890, Avg Loss2:  5.2101, Counter: 1, Best Loss:  5.1964: 100%|██████████| 157/157 [00:01<00:00, 91.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33 | Loss:  5.1996\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  4.8940, Avg Loss:  4.7244, Avg Loss1:  4.7213, Avg Loss2:  4.7274: 100%|██████████| 782/782 [00:24<00:00, 31.82it/s]\n",
      "V Loss:  4.8236, Avg Loss:  5.1930, Avg Loss1:  5.1843, Avg Loss2:  5.2017, Counter: 2, Best Loss:  5.1964: 100%|██████████| 157/157 [00:01<00:00, 88.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34 | Loss:  5.1930\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  4.6980, Avg Loss:  4.7146, Avg Loss1:  4.7114, Avg Loss2:  4.7179: 100%|██████████| 782/782 [00:23<00:00, 32.66it/s]\n",
      "V Loss:  5.0347, Avg Loss:  5.1950, Avg Loss1:  5.1855, Avg Loss2:  5.2045, Counter: 0, Best Loss:  5.1930: 100%|██████████| 157/157 [00:01<00:00, 91.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35 | Loss:  5.1950\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  4.8793, Avg Loss:  4.7043, Avg Loss1:  4.6995, Avg Loss2:  4.7091: 100%|██████████| 782/782 [00:23<00:00, 33.97it/s]\n",
      "V Loss:  5.0984, Avg Loss:  5.2000, Avg Loss1:  5.1903, Avg Loss2:  5.2097, Counter: 1, Best Loss:  5.1930: 100%|██████████| 157/157 [00:01<00:00, 89.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36 | Loss:  5.2000\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  4.7168, Avg Loss:  4.6955, Avg Loss1:  4.6907, Avg Loss2:  4.7004: 100%|██████████| 782/782 [00:24<00:00, 31.53it/s]\n",
      "V Loss:  5.0962, Avg Loss:  5.2007, Avg Loss1:  5.1932, Avg Loss2:  5.2082, Counter: 2, Best Loss:  5.1930: 100%|██████████| 157/157 [00:01<00:00, 87.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37 | Loss:  5.2007\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  4.9639, Avg Loss:  4.6855, Avg Loss1:  4.6796, Avg Loss2:  4.6915: 100%|██████████| 782/782 [00:24<00:00, 32.56it/s]\n",
      "V Loss:  5.3314, Avg Loss:  5.2033, Avg Loss1:  5.1921, Avg Loss2:  5.2145, Counter: 3, Best Loss:  5.1930: 100%|██████████| 157/157 [00:01<00:00, 88.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38 | Loss:  5.2033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lm.fit(dev_train_loader, dev_validation_loader, epochs=EPOCHS, learning_rate=LEARNING_RATE, filename='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downstream Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "downstream_train_raw_x = xdf[DEV_TRAIN_LEN+DEV_VALIDATION_LEN:]\n",
    "downstream_train_raw_y = ydf[DEV_TRAIN_LEN+DEV_VALIDATION_LEN:]\n",
    "\n",
    "downstream_validation_raw_x = xdf[:DEV_TRAIN_LEN+DEV_VALIDATION_LEN]\n",
    "downstream_validation_raw_y = ydf[:DEV_TRAIN_LEN+DEV_VALIDATION_LEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71986\n",
      "30000\n"
     ]
    }
   ],
   "source": [
    "print(len(downstream_train_raw_x))\n",
    "print(len(downstream_validation_raw_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "downstream_train_dataset = Sentences(downstream_train_raw_x, downstream_train_raw_y, word_to_idx, glove_key_to_idx)\n",
    "downstream_validation_dataset = Sentences(downstream_validation_raw_x, downstream_validation_raw_y, word_to_idx, glove_key_to_idx)\n",
    "\n",
    "downstream_train_loader = DataLoader(downstream_train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "downstream_validation_loader = DataLoader(downstream_validation_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "class NewsClassification(nn.Module):\n",
    "    def __init__(self, \n",
    "            hidden_dim: int, \n",
    "            vocab_size: int, \n",
    "            num_classes: int,\n",
    "            filename: str = None\n",
    "        ) -> None:\n",
    "\n",
    "        super(NewsClassification, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.num_classes = num_classes\n",
    "        self.elmo = ELMo(\n",
    "            glove_idx_to_vec=glove_idx_to_vec,\n",
    "            idx_to_word=idx_to_word,\n",
    "            dropout=DROPOUT, \n",
    "            num_layers=NUM_LAYERS, \n",
    "            hidden_dim=HIDDEN_DIM,\n",
    "            word_embed_dim=EMBEDDING_DIM,\n",
    "            filename=filename\n",
    "        )\n",
    "\n",
    "        for param in self.elmo.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.delta = nn.Parameter(torch.randn(1, 3))\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(2 * hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, xf: torch.Tensor, xb: torch.Tensor, l: torch.Tensor) -> torch.Tensor:\n",
    "        _, _, input, (hsf, csf), (hsb, csb) = self.elmo(xf, xb, l)\n",
    "        hsf = hsf.permute(1, 0, 2)\n",
    "        csf = csf.permute(1, 0, 2)\n",
    "        hsb = hsb.permute(1, 0, 2)\n",
    "        csb = csb.permute(1, 0, 2)\n",
    "\n",
    "        hs = torch.cat([hsf, hsb], dim=2)\n",
    "        cs = torch.cat([csf, csb], dim=2)\n",
    "\n",
    "        val = (hs + cs) / 2\n",
    "\n",
    "        input = torch.mean(input, dim=1)\n",
    "        input = torch.cat([input] * val.shape[1], dim=1).unsqueeze(1)\n",
    "\n",
    "        val = torch.cat([input, val], dim=1)\n",
    "        val = (self.delta / (torch.sum(self.delta))) @ val\n",
    "        val = val.squeeze()\n",
    "\n",
    "        x = self.linear(val)\n",
    "        return x\n",
    "\n",
    "    def fit(self, \n",
    "            train_loader: DataLoader, \n",
    "            validation_loader: DataLoader, \n",
    "            epochs: int, \n",
    "            learning_rate: float\n",
    "        ) -> None:\n",
    "\n",
    "        self.es = EarlyStopping()\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            print('----------------------------------------')\n",
    "            self._train(train_loader)\n",
    "            loss = self._evaluate(validation_loader)\n",
    "            print(f'Epoch: {epoch + 1} | Loss: {loss:7.4f}')\n",
    "            if self.es(loss, epoch):\n",
    "                break\n",
    "            if self.es.counter == 0:\n",
    "                torch.save(self.state_dict(), os.path.join(DIR, 'best.pth'))\n",
    "\n",
    "    def _call(self, xf: torch.Tensor, xb: torch.Tensor, y: torch.Tensor, l: torch.Tensor, yf: torch.Tensor, yb: torch.Tensor) -> torch.Tensor:\n",
    "        xf, xb, y, yf, yb = xf.to(DEVICE), xb.to(DEVICE), y.to(DEVICE), yf.to(DEVICE), yb.to(DEVICE)\n",
    "\n",
    "        y_hat = self(xf, xb, l)\n",
    "        y_hat = y_hat.view(-1, self.num_classes)\n",
    "        y = y.view(-1)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def _train(self, train_loader: DataLoader) -> None:\n",
    "        self.train()\n",
    "        epoch_loss = []\n",
    "        pbar = tqdm(train_loader)\n",
    "        for xf, xb, y, l, yf, yb in pbar:\n",
    "            loss = self._call(xf, xb, y, l, yf, yb)\n",
    "            epoch_loss.append(loss.item())\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            pbar.set_description(f'T Loss: {loss.item():7.4f}, Avg Loss: {np.mean(epoch_loss):7.4f}')\n",
    "\n",
    "        wandb.log({'downstream_train_loss': np.mean(epoch_loss)})\n",
    "\n",
    "    def _evaluate(self, validation_loader: DataLoader) -> float:\n",
    "        self.eval()\n",
    "        epoch_loss = []\n",
    "        pbar = tqdm(validation_loader)\n",
    "        with torch.no_grad():\n",
    "            for xf, xb, y, l, yf, yb in pbar:\n",
    "                loss = self._call(xf, xb, y, l, yf, yb)\n",
    "                epoch_loss.append(loss.item())\n",
    "                pbar.set_description(f'V Loss: {epoch_loss[-1]:7.4f}, Avg Loss: {np.mean(epoch_loss):7.4f}, Counter: {self.es.counter}, Best Loss: {self.es.best_loss:7.4f}')\n",
    "\n",
    "        wandb.log({'downstream_validation_loss': np.mean(epoch_loss)})\n",
    "        return np.mean(epoch_loss)\n",
    "\n",
    "    def _metrics(self, test_loader: DataLoader) -> None:\n",
    "        self.eval()\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        pbar = tqdm(test_loader)\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        epoch_loss = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for xf, xb, y, l, yf, yb in pbar:\n",
    "                xf, xb, y, yf, yb = xf.to(DEVICE), xb.to(DEVICE), y.to(DEVICE), yf.to(DEVICE), yb.to(DEVICE)\n",
    "\n",
    "                y_hat = self(xf, xb, l)\n",
    "                y_hat = y_hat.view(-1, self.num_classes)\n",
    "                y = y.view(-1)\n",
    "                loss = self.criterion(y_hat, y)\n",
    "\n",
    "                epoch_loss.append(loss.item())\n",
    "                y_hat = torch.argmax(y_hat, dim=1)\n",
    "                y_pred += y_hat.tolist()\n",
    "                y_true += y.tolist()\n",
    "\n",
    "        wandb.log({'downstrea_delta': self.delta.tolist()})\n",
    "\n",
    "        wandb.log({'downstream_test_loss': np.mean(epoch_loss)})\n",
    "        print(f'Test Loss: {np.mean(epoch_loss):7.4f}')\n",
    "\n",
    "        cr = classification_report(y_true, y_pred, digits=4)\n",
    "        wandb.log({'classification_report': cr})\n",
    "        print('Classification Report:', cr)\n",
    "\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        wandb.log({'confusion_matrix': cm})\n",
    "        print('Confusion Matrix:', cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_xdf, test_ydf = read_data('data/test.csv', create_unique_words=False, filter_rare_words=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "downstream_test_dataset = Sentences(test_xdf, test_ydf, word_to_idx, glove_key_to_idx)\n",
    "downstream_test_loader = DataLoader(downstream_test_dataset, batch_size=128, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 0., 0.]], device='cuda:0')\n",
      "tensor([[1., 2., 3.]], device='cuda:0')\n",
      "tensor([[0., 0., 3.]], device='cuda:0')\n",
      "tensor([[1., 1., 1.]], device='cuda:0')\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.2665, Avg Loss:  0.3733: 100%|██████████| 2250/2250 [00:20<00:00, 108.92it/s]\n",
      "V Loss:  0.0803, Avg Loss:  0.3333, Counter: 0, Best Loss:     inf: 100%|██████████| 938/938 [00:06<00:00, 137.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Loss:  0.3333\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.1081, Avg Loss:  0.3335: 100%|██████████| 2250/2250 [00:20<00:00, 110.69it/s]\n",
      "V Loss:  0.2866, Avg Loss:  0.3120, Counter: 0, Best Loss:  0.3333: 100%|██████████| 938/938 [00:06<00:00, 136.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Loss:  0.3120\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.4290, Avg Loss:  0.3209: 100%|██████████| 2250/2250 [00:20<00:00, 110.45it/s]\n",
      "V Loss:  0.1119, Avg Loss:  0.3059, Counter: 0, Best Loss:  0.3120: 100%|██████████| 938/938 [00:06<00:00, 138.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Loss:  0.3059\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.2507, Avg Loss:  0.3111: 100%|██████████| 2250/2250 [00:20<00:00, 110.35it/s]\n",
      "V Loss:  0.1609, Avg Loss:  0.2999, Counter: 0, Best Loss:  0.3059: 100%|██████████| 938/938 [00:06<00:00, 136.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Loss:  0.2999\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.4171, Avg Loss:  0.3038: 100%|██████████| 2250/2250 [00:19<00:00, 113.79it/s]\n",
      "V Loss:  0.2269, Avg Loss:  0.2983, Counter: 0, Best Loss:  0.2999: 100%|██████████| 938/938 [00:06<00:00, 137.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Loss:  0.2983\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.1024, Avg Loss:  0.2979: 100%|██████████| 2250/2250 [00:19<00:00, 117.54it/s]\n",
      "V Loss:  0.2450, Avg Loss:  0.3019, Counter: 0, Best Loss:  0.2983: 100%|██████████| 938/938 [00:07<00:00, 133.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Loss:  0.3019\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.3455, Avg Loss:  0.2936: 100%|██████████| 2250/2250 [00:20<00:00, 112.24it/s]\n",
      "V Loss:  0.1383, Avg Loss:  0.2965, Counter: 1, Best Loss:  0.2983: 100%|██████████| 938/938 [00:06<00:00, 143.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Loss:  0.2965\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.2269, Avg Loss:  0.2907: 100%|██████████| 2250/2250 [00:19<00:00, 113.97it/s]\n",
      "V Loss:  0.3272, Avg Loss:  0.2944, Counter: 0, Best Loss:  0.2965: 100%|██████████| 938/938 [00:06<00:00, 141.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Loss:  0.2944\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.2767, Avg Loss:  0.2875: 100%|██████████| 2250/2250 [00:19<00:00, 114.66it/s]\n",
      "V Loss:  0.1233, Avg Loss:  0.2973, Counter: 0, Best Loss:  0.2944: 100%|██████████| 938/938 [00:06<00:00, 137.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Loss:  0.2973\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.0713, Avg Loss:  0.2827: 100%|██████████| 2250/2250 [00:19<00:00, 115.81it/s]\n",
      "V Loss:  0.1741, Avg Loss:  0.2904, Counter: 1, Best Loss:  0.2944: 100%|██████████| 938/938 [00:06<00:00, 140.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Loss:  0.2904\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.4371, Avg Loss:  0.2819: 100%|██████████| 2250/2250 [00:19<00:00, 113.37it/s]\n",
      "V Loss:  0.1353, Avg Loss:  0.3022, Counter: 0, Best Loss:  0.2904: 100%|██████████| 938/938 [00:06<00:00, 142.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Loss:  0.3022\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.5335, Avg Loss:  0.2788: 100%|██████████| 2250/2250 [00:20<00:00, 111.31it/s]\n",
      "V Loss:  0.8151, Avg Loss:  0.2884, Counter: 1, Best Loss:  0.2904: 100%|██████████| 938/938 [00:06<00:00, 140.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Loss:  0.2884\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.3163, Avg Loss:  0.2774: 100%|██████████| 2250/2250 [00:20<00:00, 112.08it/s]\n",
      "V Loss:  0.3092, Avg Loss:  0.2934, Counter: 0, Best Loss:  0.2884: 100%|██████████| 938/938 [00:06<00:00, 138.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Loss:  0.2934\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.0863, Avg Loss:  0.2754: 100%|██████████| 2250/2250 [00:19<00:00, 112.78it/s]\n",
      "V Loss:  0.6298, Avg Loss:  0.2891, Counter: 1, Best Loss:  0.2884: 100%|██████████| 938/938 [00:06<00:00, 134.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Loss:  0.2891\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.1686, Avg Loss:  0.2730: 100%|██████████| 2250/2250 [00:19<00:00, 114.32it/s]\n",
      "V Loss:  0.0478, Avg Loss:  0.2909, Counter: 2, Best Loss:  0.2884: 100%|██████████| 938/938 [00:06<00:00, 134.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Loss:  0.2909\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.2169, Avg Loss:  0.2712: 100%|██████████| 2250/2250 [00:19<00:00, 112.70it/s]\n",
      "V Loss:  0.2064, Avg Loss:  0.2899, Counter: 3, Best Loss:  0.2884: 100%|██████████| 938/938 [00:06<00:00, 146.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Loss:  0.2899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 111.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  0.2954\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9319    0.8893    0.9101      1708\n",
      "           1     0.9539    0.9722    0.9630      1765\n",
      "           2     0.8504    0.8130    0.8313      1503\n",
      "           3     0.8235    0.8837    0.8526      1505\n",
      "\n",
      "    accuracy                         0.8929      6481\n",
      "   macro avg     0.8899    0.8896    0.8892      6481\n",
      "weighted avg     0.8938    0.8929    0.8929      6481\n",
      "\n",
      "Confusion Matrix: [[1519   41   78   70]\n",
      " [  13 1716   24   12]\n",
      " [  54   24 1222  203]\n",
      " [  44   18  113 1330]]\n",
      "tensor([[3., 0., 0.]], device='cuda:0')\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.1856, Avg Loss:  0.4428: 100%|██████████| 2250/2250 [00:18<00:00, 120.02it/s]\n",
      "V Loss:  0.1813, Avg Loss:  0.3699, Counter: 0, Best Loss:     inf: 100%|██████████| 938/938 [00:06<00:00, 138.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Loss:  0.3699\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.0723, Avg Loss:  0.3649: 100%|██████████| 2250/2250 [00:18<00:00, 120.44it/s]\n",
      "V Loss:  0.1982, Avg Loss:  0.3530, Counter: 0, Best Loss:  0.3699: 100%|██████████| 938/938 [00:06<00:00, 137.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Loss:  0.3530\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.1020, Avg Loss:  0.3479: 100%|██████████| 2250/2250 [00:19<00:00, 116.65it/s]\n",
      "V Loss:  0.2015, Avg Loss:  0.3392, Counter: 0, Best Loss:  0.3530: 100%|██████████| 938/938 [00:06<00:00, 137.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Loss:  0.3392\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.2695, Avg Loss:  0.3364: 100%|██████████| 2250/2250 [00:19<00:00, 117.93it/s]\n",
      "V Loss:  0.0889, Avg Loss:  0.3458, Counter: 0, Best Loss:  0.3392: 100%|██████████| 938/938 [00:06<00:00, 135.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Loss:  0.3458\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.3373, Avg Loss:  0.3304: 100%|██████████| 2250/2250 [00:18<00:00, 120.35it/s]\n",
      "V Loss:  0.1782, Avg Loss:  0.3345, Counter: 1, Best Loss:  0.3392: 100%|██████████| 938/938 [00:06<00:00, 138.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Loss:  0.3345\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.3592, Avg Loss:  0.3255: 100%|██████████| 2250/2250 [00:19<00:00, 115.38it/s]\n",
      "V Loss:  0.2995, Avg Loss:  0.3304, Counter: 0, Best Loss:  0.3345: 100%|██████████| 938/938 [00:06<00:00, 140.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Loss:  0.3304\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.8005, Avg Loss:  0.3200: 100%|██████████| 2250/2250 [00:18<00:00, 119.48it/s]\n",
      "V Loss:  0.4166, Avg Loss:  0.3214, Counter: 0, Best Loss:  0.3304: 100%|██████████| 938/938 [00:06<00:00, 142.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Loss:  0.3214\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.3390, Avg Loss:  0.3154: 100%|██████████| 2250/2250 [00:19<00:00, 117.98it/s]\n",
      "V Loss:  0.6730, Avg Loss:  0.3228, Counter: 0, Best Loss:  0.3214: 100%|██████████| 938/938 [00:06<00:00, 138.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Loss:  0.3228\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.5072, Avg Loss:  0.3119: 100%|██████████| 2250/2250 [00:18<00:00, 118.45it/s]\n",
      "V Loss:  0.3352, Avg Loss:  0.3208, Counter: 1, Best Loss:  0.3214: 100%|██████████| 938/938 [00:06<00:00, 138.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Loss:  0.3208\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.3299, Avg Loss:  0.3080: 100%|██████████| 2250/2250 [00:18<00:00, 119.59it/s]\n",
      "V Loss:  0.5071, Avg Loss:  0.3139, Counter: 2, Best Loss:  0.3214: 100%|██████████| 938/938 [00:06<00:00, 141.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Loss:  0.3139\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.1393, Avg Loss:  0.3052: 100%|██████████| 2250/2250 [00:18<00:00, 120.69it/s]\n",
      "V Loss:  0.2308, Avg Loss:  0.3208, Counter: 0, Best Loss:  0.3139: 100%|██████████| 938/938 [00:06<00:00, 139.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Loss:  0.3208\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.3751, Avg Loss:  0.3017: 100%|██████████| 2250/2250 [00:19<00:00, 114.24it/s]\n",
      "V Loss:  0.1337, Avg Loss:  0.3183, Counter: 1, Best Loss:  0.3139: 100%|██████████| 938/938 [00:06<00:00, 142.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Loss:  0.3183\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.0723, Avg Loss:  0.2987: 100%|██████████| 2250/2250 [00:19<00:00, 117.11it/s]\n",
      "V Loss:  0.0956, Avg Loss:  0.3134, Counter: 2, Best Loss:  0.3139: 100%|██████████| 938/938 [00:06<00:00, 134.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Loss:  0.3134\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.1435, Avg Loss:  0.2960: 100%|██████████| 2250/2250 [00:18<00:00, 120.38it/s]\n",
      "V Loss:  0.2016, Avg Loss:  0.3126, Counter: 3, Best Loss:  0.3139: 100%|██████████| 938/938 [00:06<00:00, 136.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Loss:  0.3126\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.1448, Avg Loss:  0.2937: 100%|██████████| 2250/2250 [00:19<00:00, 117.91it/s]\n",
      "V Loss:  0.4174, Avg Loss:  0.3176, Counter: 0, Best Loss:  0.3126: 100%|██████████| 938/938 [00:06<00:00, 136.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Loss:  0.3176\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.2320, Avg Loss:  0.2916: 100%|██████████| 2250/2250 [00:18<00:00, 119.60it/s]\n",
      "V Loss:  0.0583, Avg Loss:  0.3099, Counter: 1, Best Loss:  0.3126: 100%|██████████| 938/938 [00:06<00:00, 144.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Loss:  0.3099\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.2387, Avg Loss:  0.2887: 100%|██████████| 2250/2250 [00:19<00:00, 118.26it/s]\n",
      "V Loss:  0.6730, Avg Loss:  0.3095, Counter: 0, Best Loss:  0.3099: 100%|██████████| 938/938 [00:06<00:00, 136.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Loss:  0.3095\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.2238, Avg Loss:  0.2863: 100%|██████████| 2250/2250 [00:18<00:00, 119.29it/s]\n",
      "V Loss:  0.7894, Avg Loss:  0.3141, Counter: 1, Best Loss:  0.3099: 100%|██████████| 938/938 [00:06<00:00, 141.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Loss:  0.3141\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.2673, Avg Loss:  0.2848: 100%|██████████| 2250/2250 [00:19<00:00, 116.21it/s]\n",
      "V Loss:  0.1500, Avg Loss:  0.3171, Counter: 2, Best Loss:  0.3099: 100%|██████████| 938/938 [00:06<00:00, 138.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Loss:  0.3171\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.1701, Avg Loss:  0.2834: 100%|██████████| 2250/2250 [00:19<00:00, 117.27it/s]\n",
      "V Loss:  0.0774, Avg Loss:  0.3160, Counter: 3, Best Loss:  0.3099: 100%|██████████| 938/938 [00:06<00:00, 138.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Loss:  0.3160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 110.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  0.3215\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9203    0.8653    0.8920      1708\n",
      "           1     0.9403    0.9734    0.9566      1765\n",
      "           2     0.8460    0.8150    0.8302      1503\n",
      "           3     0.8269    0.8791    0.8522      1505\n",
      "\n",
      "    accuracy                         0.8863      6481\n",
      "   macro avg     0.8834    0.8832    0.8827      6481\n",
      "weighted avg     0.8868    0.8863    0.8860      6481\n",
      "\n",
      "Confusion Matrix: [[1478   66   97   67]\n",
      " [  21 1718   13   13]\n",
      " [  58   23 1225  197]\n",
      " [  49   20  113 1323]]\n",
      "tensor([[1., 2., 3.]], device='cuda:0')\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.2193, Avg Loss:  0.3761: 100%|██████████| 2250/2250 [00:19<00:00, 116.88it/s]\n",
      "V Loss:  0.4140, Avg Loss:  0.3307, Counter: 0, Best Loss:     inf: 100%|██████████| 938/938 [00:06<00:00, 138.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Loss:  0.3307\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.1121, Avg Loss:  0.3367: 100%|██████████| 2250/2250 [00:19<00:00, 117.79it/s]\n",
      "V Loss:  0.0443, Avg Loss:  0.3162, Counter: 0, Best Loss:  0.3307: 100%|██████████| 938/938 [00:07<00:00, 133.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Loss:  0.3162\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.5165, Avg Loss:  0.3227: 100%|██████████| 2250/2250 [00:19<00:00, 116.97it/s]\n",
      "V Loss:  0.4048, Avg Loss:  0.3149, Counter: 0, Best Loss:  0.3162: 100%|██████████| 938/938 [00:06<00:00, 137.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Loss:  0.3149\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.4816, Avg Loss:  0.3140: 100%|██████████| 2250/2250 [00:19<00:00, 114.35it/s]\n",
      "V Loss:  0.5013, Avg Loss:  0.3122, Counter: 0, Best Loss:  0.3149: 100%|██████████| 938/938 [00:06<00:00, 144.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Loss:  0.3122\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.1545, Avg Loss:  0.3064: 100%|██████████| 2250/2250 [00:19<00:00, 117.18it/s]\n",
      "V Loss:  0.6626, Avg Loss:  0.3007, Counter: 0, Best Loss:  0.3122: 100%|██████████| 938/938 [00:06<00:00, 138.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Loss:  0.3007\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.1476, Avg Loss:  0.3019: 100%|██████████| 2250/2250 [00:19<00:00, 117.30it/s]\n",
      "V Loss:  0.1424, Avg Loss:  0.2973, Counter: 0, Best Loss:  0.3007: 100%|██████████| 938/938 [00:06<00:00, 140.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Loss:  0.2973\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.2887, Avg Loss:  0.2971: 100%|██████████| 2250/2250 [00:18<00:00, 118.47it/s]\n",
      "V Loss:  0.3895, Avg Loss:  0.2947, Counter: 0, Best Loss:  0.2973: 100%|██████████| 938/938 [00:06<00:00, 138.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Loss:  0.2947\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.2406, Avg Loss:  0.2946: 100%|██████████| 2250/2250 [00:19<00:00, 116.82it/s]\n",
      "V Loss:  0.3381, Avg Loss:  0.2949, Counter: 0, Best Loss:  0.2947: 100%|██████████| 938/938 [00:07<00:00, 132.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Loss:  0.2949\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.3200, Avg Loss:  0.2914: 100%|██████████| 2250/2250 [00:19<00:00, 117.11it/s]\n",
      "V Loss:  0.1083, Avg Loss:  0.2892, Counter: 1, Best Loss:  0.2947: 100%|██████████| 938/938 [00:06<00:00, 137.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Loss:  0.2892\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.2122, Avg Loss:  0.2896: 100%|██████████| 2250/2250 [00:19<00:00, 115.46it/s]\n",
      "V Loss:  0.2403, Avg Loss:  0.2943, Counter: 0, Best Loss:  0.2892: 100%|██████████| 938/938 [00:06<00:00, 139.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Loss:  0.2943\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.3508, Avg Loss:  0.2852: 100%|██████████| 2250/2250 [00:19<00:00, 116.75it/s]\n",
      "V Loss:  0.1084, Avg Loss:  0.2946, Counter: 1, Best Loss:  0.2892: 100%|██████████| 938/938 [00:06<00:00, 135.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Loss:  0.2946\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.2750, Avg Loss:  0.2839: 100%|██████████| 2250/2250 [00:19<00:00, 117.10it/s]\n",
      "V Loss:  0.1251, Avg Loss:  0.2887, Counter: 2, Best Loss:  0.2892: 100%|██████████| 938/938 [00:06<00:00, 138.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Loss:  0.2887\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.2158, Avg Loss:  0.2817: 100%|██████████| 2250/2250 [00:19<00:00, 115.14it/s]\n",
      "V Loss:  0.4684, Avg Loss:  0.2984, Counter: 3, Best Loss:  0.2892: 100%|██████████| 938/938 [00:06<00:00, 139.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Loss:  0.2984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 110.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  0.2973\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9214    0.8993    0.9102      1708\n",
      "           1     0.9697    0.9598    0.9647      1765\n",
      "           2     0.8547    0.8257    0.8399      1503\n",
      "           3     0.8260    0.8864    0.8551      1505\n",
      "\n",
      "    accuracy                         0.8957      6481\n",
      "   macro avg     0.8929    0.8928    0.8925      6481\n",
      "weighted avg     0.8969    0.8957    0.8960      6481\n",
      "\n",
      "Confusion Matrix: [[1536   27   77   68]\n",
      " [  27 1694   20   24]\n",
      " [  56   17 1241  189]\n",
      " [  48    9  114 1334]]\n",
      "tensor([[0., 0., 3.]], device='cuda:0')\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.3086, Avg Loss:  0.3742: 100%|██████████| 2250/2250 [00:19<00:00, 116.69it/s]\n",
      "V Loss:  0.5008, Avg Loss:  0.3241, Counter: 0, Best Loss:     inf: 100%|██████████| 938/938 [00:06<00:00, 140.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Loss:  0.3241\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.5946, Avg Loss:  0.3344: 100%|██████████| 2250/2250 [00:19<00:00, 117.03it/s]\n",
      "V Loss:  0.3442, Avg Loss:  0.3324, Counter: 0, Best Loss:  0.3241: 100%|██████████| 938/938 [00:06<00:00, 139.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Loss:  0.3324\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.0698, Avg Loss:  0.3243: 100%|██████████| 2250/2250 [00:19<00:00, 116.47it/s]\n",
      "V Loss:  0.2839, Avg Loss:  0.3167, Counter: 1, Best Loss:  0.3241: 100%|██████████| 938/938 [00:06<00:00, 134.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Loss:  0.3167\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.1590, Avg Loss:  0.3168: 100%|██████████| 2250/2250 [00:19<00:00, 114.73it/s]\n",
      "V Loss:  0.0597, Avg Loss:  0.3041, Counter: 0, Best Loss:  0.3167: 100%|██████████| 938/938 [00:06<00:00, 138.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Loss:  0.3041\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.4286, Avg Loss:  0.3114: 100%|██████████| 2250/2250 [00:19<00:00, 114.10it/s]\n",
      "V Loss:  0.2825, Avg Loss:  0.3008, Counter: 0, Best Loss:  0.3041: 100%|██████████| 938/938 [00:07<00:00, 132.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Loss:  0.3008\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.1859, Avg Loss:  0.3064: 100%|██████████| 2250/2250 [00:19<00:00, 117.95it/s]\n",
      "V Loss:  0.3542, Avg Loss:  0.3058, Counter: 0, Best Loss:  0.3008: 100%|██████████| 938/938 [00:06<00:00, 148.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Loss:  0.3058\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.5076, Avg Loss:  0.3048: 100%|██████████| 2250/2250 [00:19<00:00, 117.91it/s]\n",
      "V Loss:  0.7846, Avg Loss:  0.3002, Counter: 1, Best Loss:  0.3008: 100%|██████████| 938/938 [00:06<00:00, 143.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Loss:  0.3002\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.1447, Avg Loss:  0.3022: 100%|██████████| 2250/2250 [00:19<00:00, 116.21it/s]\n",
      "V Loss:  0.1105, Avg Loss:  0.3046, Counter: 2, Best Loss:  0.3008: 100%|██████████| 938/938 [00:06<00:00, 138.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Loss:  0.3046\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.8399, Avg Loss:  0.2980: 100%|██████████| 2250/2250 [00:19<00:00, 116.95it/s]\n",
      "V Loss:  0.2355, Avg Loss:  0.3049, Counter: 3, Best Loss:  0.3008: 100%|██████████| 938/938 [00:06<00:00, 142.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Loss:  0.3049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 105.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  0.3090\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9145    0.8888    0.9014      1708\n",
      "           1     0.9535    0.9637    0.9586      1765\n",
      "           2     0.8118    0.8523    0.8315      1503\n",
      "           3     0.8615    0.8352    0.8482      1505\n",
      "\n",
      "    accuracy                         0.8883      6481\n",
      "   macro avg     0.8853    0.8850    0.8849      6481\n",
      "weighted avg     0.8890    0.8883    0.8884      6481\n",
      "\n",
      "Confusion Matrix: [[1518   49   93   48]\n",
      " [  21 1701   30   13]\n",
      " [  62   19 1281  141]\n",
      " [  59   15  174 1257]]\n",
      "tensor([[1., 1., 1.]], device='cuda:0')\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.3168, Avg Loss:  0.3756: 100%|██████████| 2250/2250 [00:18<00:00, 119.38it/s]\n",
      "V Loss:  0.1661, Avg Loss:  0.3420, Counter: 0, Best Loss:     inf: 100%|██████████| 938/938 [00:07<00:00, 133.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Loss:  0.3420\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  1.0549, Avg Loss:  0.3326: 100%|██████████| 2250/2250 [00:19<00:00, 114.32it/s]\n",
      "V Loss:  0.2407, Avg Loss:  0.3168, Counter: 0, Best Loss:  0.3420: 100%|██████████| 938/938 [00:06<00:00, 139.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Loss:  0.3168\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.2883, Avg Loss:  0.3209: 100%|██████████| 2250/2250 [00:19<00:00, 116.16it/s]\n",
      "V Loss:  0.1241, Avg Loss:  0.3067, Counter: 0, Best Loss:  0.3168: 100%|██████████| 938/938 [00:06<00:00, 152.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Loss:  0.3067\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.2214, Avg Loss:  0.3104: 100%|██████████| 2250/2250 [00:18<00:00, 118.57it/s]\n",
      "V Loss:  0.7316, Avg Loss:  0.3078, Counter: 0, Best Loss:  0.3067: 100%|██████████| 938/938 [00:06<00:00, 137.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Loss:  0.3078\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.3674, Avg Loss:  0.3044: 100%|██████████| 2250/2250 [00:18<00:00, 119.14it/s]\n",
      "V Loss:  0.3861, Avg Loss:  0.3363, Counter: 1, Best Loss:  0.3067: 100%|██████████| 938/938 [00:06<00:00, 143.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Loss:  0.3363\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.1560, Avg Loss:  0.3008: 100%|██████████| 2250/2250 [00:18<00:00, 121.77it/s]\n",
      "V Loss:  0.0931, Avg Loss:  0.2913, Counter: 2, Best Loss:  0.3067: 100%|██████████| 938/938 [00:06<00:00, 138.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Loss:  0.2913\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.6670, Avg Loss:  0.2955: 100%|██████████| 2250/2250 [00:19<00:00, 114.91it/s]\n",
      "V Loss:  0.2253, Avg Loss:  0.3020, Counter: 0, Best Loss:  0.2913: 100%|██████████| 938/938 [00:06<00:00, 137.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Loss:  0.3020\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.2431, Avg Loss:  0.2931: 100%|██████████| 2250/2250 [00:18<00:00, 123.17it/s]\n",
      "V Loss:  0.1303, Avg Loss:  0.3029, Counter: 1, Best Loss:  0.2913: 100%|██████████| 938/938 [00:06<00:00, 136.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Loss:  0.3029\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.1699, Avg Loss:  0.2888: 100%|██████████| 2250/2250 [00:19<00:00, 117.36it/s]\n",
      "V Loss:  0.1065, Avg Loss:  0.2875, Counter: 2, Best Loss:  0.2913: 100%|██████████| 938/938 [00:06<00:00, 134.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Loss:  0.2875\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.0615, Avg Loss:  0.2876: 100%|██████████| 2250/2250 [00:19<00:00, 116.73it/s]\n",
      "V Loss:  0.2089, Avg Loss:  0.2918, Counter: 0, Best Loss:  0.2875: 100%|██████████| 938/938 [00:06<00:00, 137.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Loss:  0.2918\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.3332, Avg Loss:  0.2853: 100%|██████████| 2250/2250 [00:18<00:00, 120.60it/s]\n",
      "V Loss:  0.1832, Avg Loss:  0.2846, Counter: 1, Best Loss:  0.2875: 100%|██████████| 938/938 [00:06<00:00, 134.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Loss:  0.2846\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.2762, Avg Loss:  0.2811: 100%|██████████| 2250/2250 [00:19<00:00, 113.65it/s]\n",
      "V Loss:  0.0933, Avg Loss:  0.2963, Counter: 0, Best Loss:  0.2846: 100%|██████████| 938/938 [00:06<00:00, 147.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Loss:  0.2963\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.0774, Avg Loss:  0.2802: 100%|██████████| 2250/2250 [00:19<00:00, 118.21it/s]\n",
      "V Loss:  0.4503, Avg Loss:  0.2975, Counter: 1, Best Loss:  0.2846: 100%|██████████| 938/938 [00:06<00:00, 141.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Loss:  0.2975\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.0741, Avg Loss:  0.2776: 100%|██████████| 2250/2250 [00:19<00:00, 118.40it/s]\n",
      "V Loss:  0.0856, Avg Loss:  0.2862, Counter: 2, Best Loss:  0.2846: 100%|██████████| 938/938 [00:06<00:00, 136.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Loss:  0.2862\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T Loss:  0.1716, Avg Loss:  0.2759: 100%|██████████| 2250/2250 [00:19<00:00, 117.91it/s]\n",
      "V Loss:  0.2279, Avg Loss:  0.2960, Counter: 3, Best Loss:  0.2846: 100%|██████████| 938/938 [00:06<00:00, 140.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Loss:  0.2960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 109.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  0.2945\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9171    0.9063    0.9117      1708\n",
      "           1     0.9649    0.9660    0.9655      1765\n",
      "           2     0.8515    0.8277    0.8394      1503\n",
      "           3     0.8415    0.8751    0.8580      1505\n",
      "\n",
      "    accuracy                         0.8971      6481\n",
      "   macro avg     0.8937    0.8938    0.8936      6481\n",
      "weighted avg     0.8973    0.8971    0.8971      6481\n",
      "\n",
      "Confusion Matrix: [[1548   28   81   51]\n",
      " [  25 1705   20   15]\n",
      " [  57   20 1244  182]\n",
      " [  58   14  116 1317]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "delta = [None, [3, 0, 0], [1, 2, 3], [0, 0, 3], [1, 1, 1]] \n",
    "for i in range(1, len(delta)):\n",
    "    delta[i] = torch.tensor(delta[i], dtype=torch.float32).reshape(1, -1).to(DEVICE)\n",
    "    print(delta[i])\n",
    "\n",
    "for d in delta:\n",
    "    nc = NewsClassification(hidden_dim=HIDDEN_DIM, \n",
    "                            vocab_size=len(word_to_idx), \n",
    "                            num_classes=NUM_CLASSES,\n",
    "                            filename=os.path.join(DIR, 'best_elmo.pth')\n",
    "                        ).to(DEVICE)\n",
    "\n",
    "    if d is not None:\n",
    "        print(d)\n",
    "        nc.delta = nn.Parameter(d, requires_grad=False)\n",
    "\n",
    "    nc.fit(downstream_train_loader, downstream_validation_loader, epochs=EPOCHS, learning_rate=LEARNING_RATE)\n",
    "\n",
    "    nc.load_state_dict(torch.load(os.path.join(DIR, 'best.pth')))\n",
    "    nc._metrics(downstream_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>downstream_test_loss</td><td>▁█▂▅▁</td></tr><tr><td>downstream_train_loss</td><td>▅▃▃▂▂▁▁▁▁█▄▃▃▃▂▂▂▂▂▁▅▃▂▂▂▂▁▅▃▃▂▂▃▃▂▂▂▂▁▁</td></tr><tr><td>downstream_validation_loss</td><td>▅▃▂▂▂▁▁▂▂█▅▅▄▄▃▄▃▃▃▄▅▃▂▂▁▂▂▄▄▂▂▃▄▃▅▂▁▁▂▂</td></tr><tr><td>upstream_train_loss</td><td>█▇▆▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>upstream_train_lossb</td><td>█▆▅▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>upstream_train_lossf</td><td>█▇▆▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>upstream_validation_loss</td><td>█▆▅▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>upstream_validation_lossb</td><td>█▆▅▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>upstream_validation_lossf</td><td>█▆▅▄▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>classification_report</td><td>              precis...</td></tr><tr><td>downstream_test_loss</td><td>0.29448</td></tr><tr><td>downstream_train_loss</td><td>0.27594</td></tr><tr><td>downstream_validation_loss</td><td>0.29602</td></tr><tr><td>upstream_train_loss</td><td>4.68555</td></tr><tr><td>upstream_train_lossb</td><td>4.69145</td></tr><tr><td>upstream_train_lossf</td><td>4.67964</td></tr><tr><td>upstream_validation_loss</td><td>5.20333</td></tr><tr><td>upstream_validation_lossb</td><td>5.21451</td></tr><tr><td>upstream_validation_lossf</td><td>5.19214</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">WordEmb</strong> at: <a href='https://wandb.ai/shu7bh/ELMO/runs/8lovywsf' target=\"_blank\">https://wandb.ai/shu7bh/ELMO/runs/8lovywsf</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230922_154116-8lovywsf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
